{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shallow_net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonkrohn/tf2/blob/master/notebooks/shallow_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXlSZrKWUrKe",
        "colab_type": "text"
      },
      "source": [
        "# Shallow Neural Network in TensorFlow 2.0\n",
        "\n",
        "A shallow neural network that classifies MNIST digits.\n",
        "\n",
        "_Remember to change your Runtime to GPU or TPU._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73o58FcYZ0zM",
        "colab_type": "text"
      },
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjWz0tCca3Xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dENc85VWa7OZ",
        "colab_type": "code",
        "outputId": "e99e8b15-f083-4fe4-c67f-ec4f4d63e720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!pip freeze | grep tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mesh-tensorflow==0.0.5\n",
            "tensorflow==1.14.0\n",
            "tensorflow-estimator==1.14.0\n",
            "tensorflow-hub==0.6.0\n",
            "tensorflow-metadata==0.14.0\n",
            "tensorflow-probability==0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ-BfzyGa9K7",
        "colab_type": "code",
        "outputId": "40ec113a-07f5-481a-f682-49adbaaf4425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "source": [
        "pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/19/0d0c7f240db7bcd6b83783b9a89a67f38584d100e23ad5ae93114be92232/tensorflow-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.12.0)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 35.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.16.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.33.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.8.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta0) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (0.15.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (2.8.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b0 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTF7OhJQbBut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Ye_R4-bo3U",
        "colab_type": "code",
        "outputId": "0406fef0-cdb3-4e28-ce9d-448697a672ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!pip freeze | grep tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mesh-tensorflow==0.0.5\n",
            "tensorflow==2.0.0b0\n",
            "tensorflow-estimator==1.14.0\n",
            "tensorflow-hub==0.6.0\n",
            "tensorflow-metadata==0.14.0\n",
            "tensorflow-probability==0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxdWaDnMbrw9",
        "colab_type": "text"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH9kdTH8bxty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6253eff4-23d6-4f2e-f78c-58154368e0dc"
      },
      "source": [
        "(X_train, y_train), (X_valid, y_valid) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ2PPkMKcC1S",
        "colab_type": "code",
        "outputId": "7ab39525-81f8-414c-a4bd-9626b072e3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_oHXNAgcGn-",
        "colab_type": "code",
        "outputId": "7027b9ab-9825-4fee-fac2-9fd41c6f7ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfHwa61ycLZc",
        "colab_type": "code",
        "outputId": "f3725d0d-b4db-4dcb-a3bf-97d3c6eb86bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[0:12]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btF3_fWOegzU",
        "colab_type": "code",
        "outputId": "db5288db-5649-4d99-cee8-a7f80bc1d2e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(5,5))\n",
        "for k in range(12):\n",
        "    plt.subplot(3, 4, k+1)\n",
        "    plt.imshow(X_train[k], cmap='Greys')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAE/CAYAAAB8TMlTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x360 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFT_CIJbep24",
        "colab_type": "code",
        "outputId": "73ea0cac-25fe-4e4a-88ec-daaed6dc5aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgQi3oC4esYo",
        "colab_type": "code",
        "outputId": "e7119a22-3077-45f2-b6c0-75c04a8db7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_valid.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwwJ04ZOettt",
        "colab_type": "code",
        "outputId": "5b8dc021-0ec4-4a48-bcec-d2cdb0197473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(X_valid[0], cmap=\"Greys\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f17fc254198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0kRfiApwg8kRfiBpP4Pc0oGVHoLWbQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKQKR_AIezMg",
        "colab_type": "code",
        "outputId": "0f8aca0b-7eff-477d-ad6f-43f7ba45dc6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_valid[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
              "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
              "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
              "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
              "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
              "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
              "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
              "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ6J0L1fe1m4",
        "colab_type": "code",
        "outputId": "8da3d8db-e8ca-4679-b593-3e8cde128055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_valid[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyMuVQvibzRu",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw0FtUpYb4Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(60000, 784).astype('float32')\n",
        "X_valid = X_valid.reshape(10000, 784).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkyGxyRIb5md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train /= 255\n",
        "X_valid /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxRjPNpNe-Gm",
        "colab_type": "code",
        "outputId": "48aba40b-d81e-49f4-db44-7377807d7b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_valid[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
              "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
              "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
              "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
              "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
              "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
              "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
              "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
              "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
              "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
              "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
              "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
              "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
              "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
              "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
              "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7rJ2C_ob6e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20zL0e_ZfDxo",
        "colab_type": "code",
        "outputId": "9cc94272-850e-4d90-8bfc-e000a49f9a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_valid[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrDbdiVqb7eN",
        "colab_type": "text"
      },
      "source": [
        "#### Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTgQAJCFb-Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    \n",
        "    keras.layers.Dense(64, activation='sigmoid', input_shape=(784,)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzSU6ALogRJv",
        "colab_type": "code",
        "outputId": "701792c1-f7f5-4ef6-d934-e543dfaba942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmKYRyaTgTTx",
        "colab_type": "code",
        "outputId": "358857b2-309d-4528-9f22-5c12949f7dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "64*784"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLgX7mIMgXVR",
        "colab_type": "code",
        "outputId": "ae4c3fd7-fafc-46ed-a3ad-aa72ca14cec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(64*784)+64"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep92qZmsgarR",
        "colab_type": "code",
        "outputId": "d747387f-44ec-4f36-94b4-4b434ae0b8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(10*64)+10"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1ljeaGgdpA",
        "colab_type": "text"
      },
      "source": [
        "#### Configure model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YI73ZvYgheG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV9-heXwgqO2",
        "colab_type": "text"
      },
      "source": [
        "#### Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtgS2Xhmgx4X",
        "colab_type": "code",
        "outputId": "b1b88c9f-3d4d-4cce-e1dd-28c9019a6ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0931 - accuracy: 0.0896 - val_loss: 0.0924 - val_accuracy: 0.0990\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0921 - accuracy: 0.1134 - val_loss: 0.0915 - val_accuracy: 0.1285\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0913 - accuracy: 0.1451 - val_loss: 0.0908 - val_accuracy: 0.1670\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0906 - accuracy: 0.1811 - val_loss: 0.0902 - val_accuracy: 0.2068\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0900 - accuracy: 0.2134 - val_loss: 0.0896 - val_accuracy: 0.2341\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0895 - accuracy: 0.2367 - val_loss: 0.0891 - val_accuracy: 0.2546\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0891 - accuracy: 0.2576 - val_loss: 0.0887 - val_accuracy: 0.2799\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0886 - accuracy: 0.2903 - val_loss: 0.0883 - val_accuracy: 0.3141\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0882 - accuracy: 0.3212 - val_loss: 0.0879 - val_accuracy: 0.3401\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0878 - accuracy: 0.3440 - val_loss: 0.0875 - val_accuracy: 0.3584\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0875 - accuracy: 0.3554 - val_loss: 0.0871 - val_accuracy: 0.3683\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0871 - accuracy: 0.3613 - val_loss: 0.0867 - val_accuracy: 0.3744\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0867 - accuracy: 0.3651 - val_loss: 0.0864 - val_accuracy: 0.3748\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0864 - accuracy: 0.3679 - val_loss: 0.0860 - val_accuracy: 0.3776\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0860 - accuracy: 0.3706 - val_loss: 0.0857 - val_accuracy: 0.3830\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0857 - accuracy: 0.3770 - val_loss: 0.0853 - val_accuracy: 0.3901\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0853 - accuracy: 0.3835 - val_loss: 0.0849 - val_accuracy: 0.3961\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0849 - accuracy: 0.3918 - val_loss: 0.0846 - val_accuracy: 0.4021\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0846 - accuracy: 0.3963 - val_loss: 0.0842 - val_accuracy: 0.4092\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0842 - accuracy: 0.4021 - val_loss: 0.0838 - val_accuracy: 0.4131\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0838 - accuracy: 0.4062 - val_loss: 0.0834 - val_accuracy: 0.4190\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0834 - accuracy: 0.4103 - val_loss: 0.0830 - val_accuracy: 0.4236\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0830 - accuracy: 0.4149 - val_loss: 0.0826 - val_accuracy: 0.4264\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0826 - accuracy: 0.4190 - val_loss: 0.0822 - val_accuracy: 0.4297\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0822 - accuracy: 0.4226 - val_loss: 0.0818 - val_accuracy: 0.4346\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0818 - accuracy: 0.4258 - val_loss: 0.0814 - val_accuracy: 0.4381\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0814 - accuracy: 0.4305 - val_loss: 0.0809 - val_accuracy: 0.4410\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0810 - accuracy: 0.4342 - val_loss: 0.0805 - val_accuracy: 0.4442\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0805 - accuracy: 0.4392 - val_loss: 0.0800 - val_accuracy: 0.4494\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0801 - accuracy: 0.4431 - val_loss: 0.0796 - val_accuracy: 0.4553\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0796 - accuracy: 0.4483 - val_loss: 0.0791 - val_accuracy: 0.4610\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0792 - accuracy: 0.4529 - val_loss: 0.0787 - val_accuracy: 0.4672\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0787 - accuracy: 0.4589 - val_loss: 0.0782 - val_accuracy: 0.4721\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0783 - accuracy: 0.4633 - val_loss: 0.0777 - val_accuracy: 0.4782\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0778 - accuracy: 0.4690 - val_loss: 0.0773 - val_accuracy: 0.4845\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0774 - accuracy: 0.4746 - val_loss: 0.0768 - val_accuracy: 0.4926\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0769 - accuracy: 0.4814 - val_loss: 0.0763 - val_accuracy: 0.4971\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0764 - accuracy: 0.4867 - val_loss: 0.0758 - val_accuracy: 0.5039\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0759 - accuracy: 0.4934 - val_loss: 0.0753 - val_accuracy: 0.5111\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0755 - accuracy: 0.4998 - val_loss: 0.0749 - val_accuracy: 0.5173\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0750 - accuracy: 0.5057 - val_loss: 0.0744 - val_accuracy: 0.5234\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0745 - accuracy: 0.5121 - val_loss: 0.0739 - val_accuracy: 0.5308\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0741 - accuracy: 0.5189 - val_loss: 0.0734 - val_accuracy: 0.5388\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0736 - accuracy: 0.5260 - val_loss: 0.0729 - val_accuracy: 0.5462\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0731 - accuracy: 0.5327 - val_loss: 0.0724 - val_accuracy: 0.5533\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0726 - accuracy: 0.5388 - val_loss: 0.0719 - val_accuracy: 0.5620\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0722 - accuracy: 0.5461 - val_loss: 0.0715 - val_accuracy: 0.5686\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0717 - accuracy: 0.5548 - val_loss: 0.0710 - val_accuracy: 0.5748\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0712 - accuracy: 0.5614 - val_loss: 0.0705 - val_accuracy: 0.5833\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0707 - accuracy: 0.5676 - val_loss: 0.0700 - val_accuracy: 0.5905\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0703 - accuracy: 0.5747 - val_loss: 0.0695 - val_accuracy: 0.5967\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0698 - accuracy: 0.5819 - val_loss: 0.0691 - val_accuracy: 0.6040\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0694 - accuracy: 0.5887 - val_loss: 0.0686 - val_accuracy: 0.6108\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0689 - accuracy: 0.5971 - val_loss: 0.0681 - val_accuracy: 0.6166\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0684 - accuracy: 0.6034 - val_loss: 0.0677 - val_accuracy: 0.6245\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0680 - accuracy: 0.6107 - val_loss: 0.0672 - val_accuracy: 0.6306\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0675 - accuracy: 0.6168 - val_loss: 0.0667 - val_accuracy: 0.6360\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0671 - accuracy: 0.6232 - val_loss: 0.0663 - val_accuracy: 0.6420\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0666 - accuracy: 0.6297 - val_loss: 0.0658 - val_accuracy: 0.6475\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0661 - accuracy: 0.6360 - val_loss: 0.0653 - val_accuracy: 0.6525\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0657 - accuracy: 0.6416 - val_loss: 0.0649 - val_accuracy: 0.6575\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0652 - accuracy: 0.6471 - val_loss: 0.0644 - val_accuracy: 0.6629\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0648 - accuracy: 0.6515 - val_loss: 0.0640 - val_accuracy: 0.6691\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0644 - accuracy: 0.6563 - val_loss: 0.0635 - val_accuracy: 0.6736\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0639 - accuracy: 0.6607 - val_loss: 0.0631 - val_accuracy: 0.6779\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0635 - accuracy: 0.6653 - val_loss: 0.0626 - val_accuracy: 0.6812\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0630 - accuracy: 0.6699 - val_loss: 0.0622 - val_accuracy: 0.6850\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0626 - accuracy: 0.6740 - val_loss: 0.0617 - val_accuracy: 0.6891\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0622 - accuracy: 0.6772 - val_loss: 0.0613 - val_accuracy: 0.6928\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0617 - accuracy: 0.6817 - val_loss: 0.0608 - val_accuracy: 0.6961\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0613 - accuracy: 0.6855 - val_loss: 0.0604 - val_accuracy: 0.6982\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0608 - accuracy: 0.6884 - val_loss: 0.0600 - val_accuracy: 0.7014\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0604 - accuracy: 0.6911 - val_loss: 0.0595 - val_accuracy: 0.7038\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0600 - accuracy: 0.6935 - val_loss: 0.0591 - val_accuracy: 0.7065\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0596 - accuracy: 0.6973 - val_loss: 0.0587 - val_accuracy: 0.7079\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0591 - accuracy: 0.6995 - val_loss: 0.0582 - val_accuracy: 0.7104\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0587 - accuracy: 0.7018 - val_loss: 0.0578 - val_accuracy: 0.7130\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0583 - accuracy: 0.7047 - val_loss: 0.0574 - val_accuracy: 0.7154\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0579 - accuracy: 0.7069 - val_loss: 0.0569 - val_accuracy: 0.7171\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0574 - accuracy: 0.7088 - val_loss: 0.0565 - val_accuracy: 0.7197\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0570 - accuracy: 0.7112 - val_loss: 0.0561 - val_accuracy: 0.7210\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0566 - accuracy: 0.7131 - val_loss: 0.0557 - val_accuracy: 0.7226\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0562 - accuracy: 0.7154 - val_loss: 0.0552 - val_accuracy: 0.7245\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0558 - accuracy: 0.7167 - val_loss: 0.0548 - val_accuracy: 0.7263\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0554 - accuracy: 0.7190 - val_loss: 0.0544 - val_accuracy: 0.7279\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0549 - accuracy: 0.7201 - val_loss: 0.0540 - val_accuracy: 0.7288\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0545 - accuracy: 0.7222 - val_loss: 0.0536 - val_accuracy: 0.7323\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0541 - accuracy: 0.7237 - val_loss: 0.0532 - val_accuracy: 0.7347\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0537 - accuracy: 0.7256 - val_loss: 0.0528 - val_accuracy: 0.7359\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0534 - accuracy: 0.7272 - val_loss: 0.0524 - val_accuracy: 0.7372\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0530 - accuracy: 0.7289 - val_loss: 0.0520 - val_accuracy: 0.7383\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0526 - accuracy: 0.7304 - val_loss: 0.0516 - val_accuracy: 0.7404\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0522 - accuracy: 0.7322 - val_loss: 0.0512 - val_accuracy: 0.7422\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0518 - accuracy: 0.7336 - val_loss: 0.0508 - val_accuracy: 0.7443\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0514 - accuracy: 0.7354 - val_loss: 0.0505 - val_accuracy: 0.7456\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0511 - accuracy: 0.7367 - val_loss: 0.0501 - val_accuracy: 0.7469\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0507 - accuracy: 0.7380 - val_loss: 0.0497 - val_accuracy: 0.7486\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0503 - accuracy: 0.7393 - val_loss: 0.0494 - val_accuracy: 0.7500\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0500 - accuracy: 0.7407 - val_loss: 0.0490 - val_accuracy: 0.7506\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0496 - accuracy: 0.7419 - val_loss: 0.0486 - val_accuracy: 0.7520\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0492 - accuracy: 0.7437 - val_loss: 0.0483 - val_accuracy: 0.7538\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0489 - accuracy: 0.7452 - val_loss: 0.0479 - val_accuracy: 0.7553\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0486 - accuracy: 0.7465 - val_loss: 0.0476 - val_accuracy: 0.7565\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0482 - accuracy: 0.7483 - val_loss: 0.0472 - val_accuracy: 0.7578\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0479 - accuracy: 0.7495 - val_loss: 0.0469 - val_accuracy: 0.7596\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0476 - accuracy: 0.7509 - val_loss: 0.0466 - val_accuracy: 0.7608\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0472 - accuracy: 0.7523 - val_loss: 0.0463 - val_accuracy: 0.7618\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0469 - accuracy: 0.7535 - val_loss: 0.0459 - val_accuracy: 0.7630\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0466 - accuracy: 0.7549 - val_loss: 0.0456 - val_accuracy: 0.7637\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0463 - accuracy: 0.7561 - val_loss: 0.0453 - val_accuracy: 0.7639\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0460 - accuracy: 0.7574 - val_loss: 0.0450 - val_accuracy: 0.7663\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0457 - accuracy: 0.7585 - val_loss: 0.0447 - val_accuracy: 0.7676\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0454 - accuracy: 0.7596 - val_loss: 0.0444 - val_accuracy: 0.7684\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0451 - accuracy: 0.7606 - val_loss: 0.0441 - val_accuracy: 0.7692\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0448 - accuracy: 0.7618 - val_loss: 0.0438 - val_accuracy: 0.7701\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0445 - accuracy: 0.7632 - val_loss: 0.0435 - val_accuracy: 0.7715\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0442 - accuracy: 0.7640 - val_loss: 0.0432 - val_accuracy: 0.7728\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0440 - accuracy: 0.7650 - val_loss: 0.0430 - val_accuracy: 0.7739\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0437 - accuracy: 0.7660 - val_loss: 0.0427 - val_accuracy: 0.7748\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0434 - accuracy: 0.7669 - val_loss: 0.0424 - val_accuracy: 0.7758\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0432 - accuracy: 0.7679 - val_loss: 0.0422 - val_accuracy: 0.7768\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0429 - accuracy: 0.7689 - val_loss: 0.0419 - val_accuracy: 0.7778\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0426 - accuracy: 0.7693 - val_loss: 0.0416 - val_accuracy: 0.7788\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0424 - accuracy: 0.7702 - val_loss: 0.0414 - val_accuracy: 0.7801\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0421 - accuracy: 0.7709 - val_loss: 0.0411 - val_accuracy: 0.7808\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0419 - accuracy: 0.7717 - val_loss: 0.0409 - val_accuracy: 0.7818\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0417 - accuracy: 0.7723 - val_loss: 0.0407 - val_accuracy: 0.7824\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0414 - accuracy: 0.7730 - val_loss: 0.0404 - val_accuracy: 0.7832\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0412 - accuracy: 0.7738 - val_loss: 0.0402 - val_accuracy: 0.7836\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0410 - accuracy: 0.7743 - val_loss: 0.0400 - val_accuracy: 0.7845\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0407 - accuracy: 0.7748 - val_loss: 0.0397 - val_accuracy: 0.7859\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0405 - accuracy: 0.7757 - val_loss: 0.0395 - val_accuracy: 0.7867\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0403 - accuracy: 0.7761 - val_loss: 0.0393 - val_accuracy: 0.7872\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0401 - accuracy: 0.7767 - val_loss: 0.0391 - val_accuracy: 0.7876\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0399 - accuracy: 0.7772 - val_loss: 0.0389 - val_accuracy: 0.7881\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0397 - accuracy: 0.7775 - val_loss: 0.0387 - val_accuracy: 0.7883\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0395 - accuracy: 0.7781 - val_loss: 0.0385 - val_accuracy: 0.7887\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0393 - accuracy: 0.7788 - val_loss: 0.0382 - val_accuracy: 0.7895\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0391 - accuracy: 0.7794 - val_loss: 0.0380 - val_accuracy: 0.7902\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0389 - accuracy: 0.7800 - val_loss: 0.0378 - val_accuracy: 0.7912\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0387 - accuracy: 0.7804 - val_loss: 0.0376 - val_accuracy: 0.7924\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0385 - accuracy: 0.7810 - val_loss: 0.0374 - val_accuracy: 0.7928\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0383 - accuracy: 0.7813 - val_loss: 0.0373 - val_accuracy: 0.7933\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0381 - accuracy: 0.7819 - val_loss: 0.0371 - val_accuracy: 0.7938\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0379 - accuracy: 0.7820 - val_loss: 0.0369 - val_accuracy: 0.7945\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0377 - accuracy: 0.7828 - val_loss: 0.0367 - val_accuracy: 0.7950\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0375 - accuracy: 0.7832 - val_loss: 0.0365 - val_accuracy: 0.7953\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0373 - accuracy: 0.7836 - val_loss: 0.0363 - val_accuracy: 0.7956\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0372 - accuracy: 0.7843 - val_loss: 0.0361 - val_accuracy: 0.7959\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0370 - accuracy: 0.7846 - val_loss: 0.0360 - val_accuracy: 0.7967\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0368 - accuracy: 0.7851 - val_loss: 0.0358 - val_accuracy: 0.7976\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0366 - accuracy: 0.7855 - val_loss: 0.0356 - val_accuracy: 0.7981\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0365 - accuracy: 0.7861 - val_loss: 0.0354 - val_accuracy: 0.7986\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0363 - accuracy: 0.7865 - val_loss: 0.0353 - val_accuracy: 0.7990\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0361 - accuracy: 0.7872 - val_loss: 0.0351 - val_accuracy: 0.7995\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0360 - accuracy: 0.7878 - val_loss: 0.0349 - val_accuracy: 0.8001\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0358 - accuracy: 0.7886 - val_loss: 0.0347 - val_accuracy: 0.8010\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0356 - accuracy: 0.7891 - val_loss: 0.0346 - val_accuracy: 0.8015\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0354 - accuracy: 0.7896 - val_loss: 0.0344 - val_accuracy: 0.8027\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0353 - accuracy: 0.7906 - val_loss: 0.0342 - val_accuracy: 0.8033\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0351 - accuracy: 0.7914 - val_loss: 0.0341 - val_accuracy: 0.8041\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0350 - accuracy: 0.7923 - val_loss: 0.0339 - val_accuracy: 0.8051\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0348 - accuracy: 0.7933 - val_loss: 0.0338 - val_accuracy: 0.8062\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0346 - accuracy: 0.7944 - val_loss: 0.0336 - val_accuracy: 0.8073\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0345 - accuracy: 0.7957 - val_loss: 0.0334 - val_accuracy: 0.8086\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0343 - accuracy: 0.7971 - val_loss: 0.0333 - val_accuracy: 0.8097\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0342 - accuracy: 0.7983 - val_loss: 0.0331 - val_accuracy: 0.8111\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0340 - accuracy: 0.8000 - val_loss: 0.0330 - val_accuracy: 0.8130\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0339 - accuracy: 0.8011 - val_loss: 0.0328 - val_accuracy: 0.8150\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0337 - accuracy: 0.8027 - val_loss: 0.0327 - val_accuracy: 0.8159\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0336 - accuracy: 0.8045 - val_loss: 0.0325 - val_accuracy: 0.8173\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0334 - accuracy: 0.8060 - val_loss: 0.0323 - val_accuracy: 0.8179\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0333 - accuracy: 0.8079 - val_loss: 0.0322 - val_accuracy: 0.8199\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0331 - accuracy: 0.8095 - val_loss: 0.0321 - val_accuracy: 0.8213\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0330 - accuracy: 0.8109 - val_loss: 0.0319 - val_accuracy: 0.8229\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0328 - accuracy: 0.8124 - val_loss: 0.0318 - val_accuracy: 0.8244\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0327 - accuracy: 0.8137 - val_loss: 0.0316 - val_accuracy: 0.8257\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0325 - accuracy: 0.8153 - val_loss: 0.0315 - val_accuracy: 0.8267\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0324 - accuracy: 0.8168 - val_loss: 0.0313 - val_accuracy: 0.8288\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0323 - accuracy: 0.8182 - val_loss: 0.0312 - val_accuracy: 0.8299\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0321 - accuracy: 0.8197 - val_loss: 0.0310 - val_accuracy: 0.8311\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0320 - accuracy: 0.8212 - val_loss: 0.0309 - val_accuracy: 0.8328\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0318 - accuracy: 0.8224 - val_loss: 0.0308 - val_accuracy: 0.8337\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0317 - accuracy: 0.8238 - val_loss: 0.0306 - val_accuracy: 0.8344\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0316 - accuracy: 0.8252 - val_loss: 0.0305 - val_accuracy: 0.8353\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0314 - accuracy: 0.8263 - val_loss: 0.0304 - val_accuracy: 0.8369\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0313 - accuracy: 0.8276 - val_loss: 0.0302 - val_accuracy: 0.8381\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0312 - accuracy: 0.8287 - val_loss: 0.0301 - val_accuracy: 0.8392\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0310 - accuracy: 0.8300 - val_loss: 0.0300 - val_accuracy: 0.8403\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0309 - accuracy: 0.8313 - val_loss: 0.0298 - val_accuracy: 0.8413\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0308 - accuracy: 0.8323 - val_loss: 0.0297 - val_accuracy: 0.8419\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0307 - accuracy: 0.8333 - val_loss: 0.0296 - val_accuracy: 0.8427\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0305 - accuracy: 0.8342 - val_loss: 0.0295 - val_accuracy: 0.8437\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0304 - accuracy: 0.8352 - val_loss: 0.0293 - val_accuracy: 0.8449\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0303 - accuracy: 0.8362 - val_loss: 0.0292 - val_accuracy: 0.8457\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0302 - accuracy: 0.8372 - val_loss: 0.0291 - val_accuracy: 0.8466\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0300 - accuracy: 0.8384 - val_loss: 0.0290 - val_accuracy: 0.8475\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0299 - accuracy: 0.8396 - val_loss: 0.0288 - val_accuracy: 0.8486\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0298 - accuracy: 0.8404 - val_loss: 0.0287 - val_accuracy: 0.8495\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0297 - accuracy: 0.8411 - val_loss: 0.0286 - val_accuracy: 0.8503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f17f719ef98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhKX6mHjjrV",
        "colab_type": "text"
      },
      "source": [
        "#### Performing Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iobxsDEPkenJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_0 = X_valid[0].reshape(1, 784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUc2kS7DkieS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "626226c1-bcca-465f-f275-2f7acd6f724e"
      },
      "source": [
        "model.predict(valid_0)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00848659, 0.00206054, 0.00527265, 0.00809885, 0.00749474,\n",
              "        0.02288202, 0.00100921, 0.8958281 , 0.00767344, 0.04119389]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAyaOgPdkldm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43a199c3-c002-4e2d-c17d-edc80c05e4f4"
      },
      "source": [
        "model.predict_classes(valid_0)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWAx8Xs_kolW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}