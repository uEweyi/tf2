{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shallow_net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonkrohn/tf2/blob/master/shallow_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXlSZrKWUrKe",
        "colab_type": "text"
      },
      "source": [
        "# Shallow Neural Network in TensorFlow 2.0\n",
        "\n",
        "A shallow neural network that classifies MNIST digits.\n",
        "\n",
        "_Remember to change your Runtime to GPU or TPU._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73o58FcYZ0zM",
        "colab_type": "text"
      },
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjWz0tCca3Xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dENc85VWa7OZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1d564f2a-21dc-4f12-9c02-2ac66943d42b"
      },
      "source": [
        "!pip freeze | grep tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mesh-tensorflow==0.0.5\n",
            "tensorflow==1.14.0rc1\n",
            "tensorflow-estimator==1.14.0rc1\n",
            "tensorflow-hub==0.4.0\n",
            "tensorflow-metadata==0.13.0\n",
            "tensorflow-probability==0.7.0rc0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ-BfzyGa9K7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "91bd6cb1-e6c6-45c6-dcaf-9efba3ff15c2"
      },
      "source": [
        "pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/19/0d0c7f240db7bcd6b83783b9a89a67f38584d100e23ad5ae93114be92232/tensorflow-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 82kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.16.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.2.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 23.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.11.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.33.4)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 40.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta0) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.1.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.14.0rc1\n",
            "    Uninstalling tensorflow-1.14.0rc1:\n",
            "      Successfully uninstalled tensorflow-1.14.0rc1\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b0 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTF7OhJQbBut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Ye_R4-bo3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "aa497ce1-27df-4781-b302-6dc9ae8578d4"
      },
      "source": [
        "!pip freeze | grep tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mesh-tensorflow==0.0.5\n",
            "tensorflow==2.0.0b0\n",
            "tensorflow-estimator==1.14.0rc1\n",
            "tensorflow-hub==0.4.0\n",
            "tensorflow-metadata==0.13.0\n",
            "tensorflow-probability==0.7.0rc0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxdWaDnMbrw9",
        "colab_type": "text"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH9kdTH8bxty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_valid, y_valid) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ2PPkMKcC1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da011821-7f02-43bb-89a5-231259253f08"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_oHXNAgcGn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c456fa5e-58ab-4eba-f22d-2692d49b1b84"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfHwa61ycLZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7303d0e5-81f4-40ed-8c91-2e41bb1ec763"
      },
      "source": [
        "y_train[0:12]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btF3_fWOegzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "e9c8ad6d-fc00-4d44-8347-84f6fc92d16e"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(5,5))\n",
        "for k in range(12):\n",
        "    plt.subplot(3, 4, k+1)\n",
        "    plt.imshow(X_train[k], cmap='Greys')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAE/CAYAAAB8TMlTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x360 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFT_CIJbep24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d19e27fc-2323-4677-c5c3-06c60bf41127"
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgQi3oC4esYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8126dd5d-956d-4864-843f-2c3277d8b9d5"
      },
      "source": [
        "y_valid.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwwJ04ZOettt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "80d9549e-5637-465b-8b0c-240d5f0d28aa"
      },
      "source": [
        "plt.imshow(X_valid[0], cmap=\"Greys\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fef4f574320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0kRfiApwg8kRfiBpP4Pc0oGVHoLWbQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKQKR_AIezMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d71f888d-7bf5-4149-e950-b2d38c307435"
      },
      "source": [
        "X_valid[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
              "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
              "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
              "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
              "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
              "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
              "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
              "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ6J0L1fe1m4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf2dcda6-aaa5-4554-802f-10bdba8ad5d0"
      },
      "source": [
        "y_valid[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyMuVQvibzRu",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw0FtUpYb4Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(60000, 784).astype('float32')\n",
        "X_valid = X_valid.reshape(10000, 784).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkyGxyRIb5md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train /= 255\n",
        "X_valid /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxRjPNpNe-Gm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2490a975-ae0b-45f6-bcfb-8d0ed1da4f28"
      },
      "source": [
        "X_valid[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
              "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
              "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
              "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
              "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
              "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
              "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
              "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
              "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
              "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
              "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
              "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
              "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
              "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
              "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
              "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7rJ2C_ob6e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20zL0e_ZfDxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea803610-fd43-4faa-9d21-6d1bba4fb325"
      },
      "source": [
        "y_valid[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrDbdiVqb7eN",
        "colab_type": "text"
      },
      "source": [
        "#### Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTgQAJCFb-Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    \n",
        "    keras.layers.Dense(64, activation='sigmoid', input_shape=(784,)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzSU6ALogRJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "37bffefd-6188-4757-a76b-505b7bec5e84"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmKYRyaTgTTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd359de0-17cf-4b90-8e6e-882c35da062f"
      },
      "source": [
        "64*784"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLgX7mIMgXVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62c0105a-19c7-4459-dc5d-8aa9d44185e7"
      },
      "source": [
        "(64*784)+64"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep92qZmsgarR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "243e0818-f771-415c-c740-526d5d3cc80c"
      },
      "source": [
        "(10*64)+10"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1ljeaGgdpA",
        "colab_type": "text"
      },
      "source": [
        "#### Configure model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YI73ZvYgheG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV9-heXwgqO2",
        "colab_type": "text"
      },
      "source": [
        "#### Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtgS2Xhmgx4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "558b7490-edb8-4bb0-e453-a4897feab4d3"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0930 - accuracy: 0.0651 - val_loss: 0.0926 - val_accuracy: 0.0558\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0922 - accuracy: 0.0657 - val_loss: 0.0920 - val_accuracy: 0.0651\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0917 - accuracy: 0.0794 - val_loss: 0.0916 - val_accuracy: 0.0784\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0913 - accuracy: 0.0948 - val_loss: 0.0912 - val_accuracy: 0.0942\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0909 - accuracy: 0.1144 - val_loss: 0.0908 - val_accuracy: 0.1189\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0905 - accuracy: 0.1399 - val_loss: 0.0904 - val_accuracy: 0.1495\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0902 - accuracy: 0.1686 - val_loss: 0.0901 - val_accuracy: 0.1806\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0899 - accuracy: 0.1947 - val_loss: 0.0898 - val_accuracy: 0.2066\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0896 - accuracy: 0.2162 - val_loss: 0.0895 - val_accuracy: 0.2279\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0893 - accuracy: 0.2358 - val_loss: 0.0892 - val_accuracy: 0.2459\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0890 - accuracy: 0.2531 - val_loss: 0.0889 - val_accuracy: 0.2624\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0886 - accuracy: 0.2700 - val_loss: 0.0885 - val_accuracy: 0.2788\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0883 - accuracy: 0.2845 - val_loss: 0.0882 - val_accuracy: 0.2923\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0880 - accuracy: 0.2965 - val_loss: 0.0879 - val_accuracy: 0.3035\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0877 - accuracy: 0.3068 - val_loss: 0.0875 - val_accuracy: 0.3124\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0873 - accuracy: 0.3157 - val_loss: 0.0872 - val_accuracy: 0.3224\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0870 - accuracy: 0.3246 - val_loss: 0.0868 - val_accuracy: 0.3323\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0867 - accuracy: 0.3318 - val_loss: 0.0865 - val_accuracy: 0.3391\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0863 - accuracy: 0.3376 - val_loss: 0.0861 - val_accuracy: 0.3458\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0859 - accuracy: 0.3438 - val_loss: 0.0857 - val_accuracy: 0.3521\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0856 - accuracy: 0.3487 - val_loss: 0.0853 - val_accuracy: 0.3589\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0852 - accuracy: 0.3544 - val_loss: 0.0849 - val_accuracy: 0.3657\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0848 - accuracy: 0.3597 - val_loss: 0.0845 - val_accuracy: 0.3721\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0844 - accuracy: 0.3642 - val_loss: 0.0841 - val_accuracy: 0.3782\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0840 - accuracy: 0.3697 - val_loss: 0.0837 - val_accuracy: 0.3840\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0836 - accuracy: 0.3750 - val_loss: 0.0833 - val_accuracy: 0.3904\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0832 - accuracy: 0.3823 - val_loss: 0.0829 - val_accuracy: 0.3951\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0827 - accuracy: 0.3870 - val_loss: 0.0824 - val_accuracy: 0.4006\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0823 - accuracy: 0.3921 - val_loss: 0.0820 - val_accuracy: 0.4058\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0819 - accuracy: 0.3966 - val_loss: 0.0815 - val_accuracy: 0.4110\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0814 - accuracy: 0.4036 - val_loss: 0.0811 - val_accuracy: 0.4166\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0810 - accuracy: 0.4091 - val_loss: 0.0806 - val_accuracy: 0.4217\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0806 - accuracy: 0.4153 - val_loss: 0.0802 - val_accuracy: 0.4264\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0801 - accuracy: 0.4201 - val_loss: 0.0797 - val_accuracy: 0.4320\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0797 - accuracy: 0.4264 - val_loss: 0.0793 - val_accuracy: 0.4356\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0792 - accuracy: 0.4318 - val_loss: 0.0788 - val_accuracy: 0.4402\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0787 - accuracy: 0.4376 - val_loss: 0.0783 - val_accuracy: 0.4458\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0783 - accuracy: 0.4427 - val_loss: 0.0779 - val_accuracy: 0.4521\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0778 - accuracy: 0.4480 - val_loss: 0.0774 - val_accuracy: 0.4570\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0774 - accuracy: 0.4530 - val_loss: 0.0769 - val_accuracy: 0.4626\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0769 - accuracy: 0.4581 - val_loss: 0.0764 - val_accuracy: 0.4686\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0764 - accuracy: 0.4627 - val_loss: 0.0760 - val_accuracy: 0.4732\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0760 - accuracy: 0.4668 - val_loss: 0.0755 - val_accuracy: 0.4782\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0755 - accuracy: 0.4711 - val_loss: 0.0750 - val_accuracy: 0.4830\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0750 - accuracy: 0.4753 - val_loss: 0.0746 - val_accuracy: 0.4865\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0746 - accuracy: 0.4803 - val_loss: 0.0741 - val_accuracy: 0.4893\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0741 - accuracy: 0.4839 - val_loss: 0.0736 - val_accuracy: 0.4937\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0737 - accuracy: 0.4877 - val_loss: 0.0732 - val_accuracy: 0.4968\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0732 - accuracy: 0.4921 - val_loss: 0.0727 - val_accuracy: 0.5005\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0727 - accuracy: 0.4958 - val_loss: 0.0722 - val_accuracy: 0.5046\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0723 - accuracy: 0.4989 - val_loss: 0.0718 - val_accuracy: 0.5078\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0718 - accuracy: 0.5037 - val_loss: 0.0713 - val_accuracy: 0.5112\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0714 - accuracy: 0.5073 - val_loss: 0.0708 - val_accuracy: 0.5151\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0709 - accuracy: 0.5111 - val_loss: 0.0704 - val_accuracy: 0.5189\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0705 - accuracy: 0.5156 - val_loss: 0.0699 - val_accuracy: 0.5229\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0700 - accuracy: 0.5196 - val_loss: 0.0695 - val_accuracy: 0.5272\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0696 - accuracy: 0.5236 - val_loss: 0.0690 - val_accuracy: 0.5318\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0691 - accuracy: 0.5280 - val_loss: 0.0686 - val_accuracy: 0.5369\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0687 - accuracy: 0.5312 - val_loss: 0.0681 - val_accuracy: 0.5423\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0682 - accuracy: 0.5368 - val_loss: 0.0677 - val_accuracy: 0.5466\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0678 - accuracy: 0.5405 - val_loss: 0.0672 - val_accuracy: 0.5518\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0674 - accuracy: 0.5449 - val_loss: 0.0668 - val_accuracy: 0.5567\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0669 - accuracy: 0.5490 - val_loss: 0.0664 - val_accuracy: 0.5615\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0665 - accuracy: 0.5533 - val_loss: 0.0659 - val_accuracy: 0.5671\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0661 - accuracy: 0.5588 - val_loss: 0.0655 - val_accuracy: 0.5712\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0657 - accuracy: 0.5638 - val_loss: 0.0651 - val_accuracy: 0.5756\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0652 - accuracy: 0.5685 - val_loss: 0.0646 - val_accuracy: 0.5799\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0648 - accuracy: 0.5735 - val_loss: 0.0642 - val_accuracy: 0.5842\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0644 - accuracy: 0.5781 - val_loss: 0.0638 - val_accuracy: 0.5883\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0640 - accuracy: 0.5835 - val_loss: 0.0634 - val_accuracy: 0.5928\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0636 - accuracy: 0.5879 - val_loss: 0.0629 - val_accuracy: 0.5966\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0632 - accuracy: 0.5918 - val_loss: 0.0625 - val_accuracy: 0.6013\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0627 - accuracy: 0.5962 - val_loss: 0.0621 - val_accuracy: 0.6064\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0623 - accuracy: 0.6007 - val_loss: 0.0617 - val_accuracy: 0.6107\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0619 - accuracy: 0.6047 - val_loss: 0.0613 - val_accuracy: 0.6154\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0615 - accuracy: 0.6090 - val_loss: 0.0609 - val_accuracy: 0.6200\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0611 - accuracy: 0.6132 - val_loss: 0.0605 - val_accuracy: 0.6239\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0607 - accuracy: 0.6178 - val_loss: 0.0601 - val_accuracy: 0.6277\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0603 - accuracy: 0.6209 - val_loss: 0.0597 - val_accuracy: 0.6310\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0600 - accuracy: 0.6248 - val_loss: 0.0593 - val_accuracy: 0.6337\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0596 - accuracy: 0.6285 - val_loss: 0.0589 - val_accuracy: 0.6378\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0592 - accuracy: 0.6328 - val_loss: 0.0585 - val_accuracy: 0.6404\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0588 - accuracy: 0.6365 - val_loss: 0.0581 - val_accuracy: 0.6444\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0584 - accuracy: 0.6395 - val_loss: 0.0577 - val_accuracy: 0.6474\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0580 - accuracy: 0.6432 - val_loss: 0.0574 - val_accuracy: 0.6505\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0577 - accuracy: 0.6460 - val_loss: 0.0570 - val_accuracy: 0.6542\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0573 - accuracy: 0.6491 - val_loss: 0.0566 - val_accuracy: 0.6575\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0569 - accuracy: 0.6531 - val_loss: 0.0562 - val_accuracy: 0.6602\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0566 - accuracy: 0.6555 - val_loss: 0.0559 - val_accuracy: 0.6633\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0562 - accuracy: 0.6594 - val_loss: 0.0555 - val_accuracy: 0.6659\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0558 - accuracy: 0.6623 - val_loss: 0.0551 - val_accuracy: 0.6683\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0555 - accuracy: 0.6654 - val_loss: 0.0548 - val_accuracy: 0.6720\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0551 - accuracy: 0.6682 - val_loss: 0.0544 - val_accuracy: 0.6750\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0548 - accuracy: 0.6722 - val_loss: 0.0540 - val_accuracy: 0.6775\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0544 - accuracy: 0.6750 - val_loss: 0.0537 - val_accuracy: 0.6794\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0541 - accuracy: 0.6779 - val_loss: 0.0533 - val_accuracy: 0.6829\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0537 - accuracy: 0.6817 - val_loss: 0.0530 - val_accuracy: 0.6862\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0534 - accuracy: 0.6838 - val_loss: 0.0526 - val_accuracy: 0.6899\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0531 - accuracy: 0.6874 - val_loss: 0.0523 - val_accuracy: 0.6937\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0527 - accuracy: 0.6904 - val_loss: 0.0519 - val_accuracy: 0.6967\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0524 - accuracy: 0.6938 - val_loss: 0.0516 - val_accuracy: 0.6993\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0520 - accuracy: 0.6962 - val_loss: 0.0513 - val_accuracy: 0.7022\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0517 - accuracy: 0.6992 - val_loss: 0.0509 - val_accuracy: 0.7060\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0514 - accuracy: 0.7025 - val_loss: 0.0506 - val_accuracy: 0.7086\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0511 - accuracy: 0.7051 - val_loss: 0.0503 - val_accuracy: 0.7114\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0507 - accuracy: 0.7071 - val_loss: 0.0500 - val_accuracy: 0.7140\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0504 - accuracy: 0.7102 - val_loss: 0.0496 - val_accuracy: 0.7169\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0501 - accuracy: 0.7125 - val_loss: 0.0493 - val_accuracy: 0.7199\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0498 - accuracy: 0.7154 - val_loss: 0.0490 - val_accuracy: 0.7222\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0495 - accuracy: 0.7179 - val_loss: 0.0487 - val_accuracy: 0.7253\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0492 - accuracy: 0.7202 - val_loss: 0.0484 - val_accuracy: 0.7274\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.0489 - accuracy: 0.7224 - val_loss: 0.0480 - val_accuracy: 0.7294\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0486 - accuracy: 0.7247 - val_loss: 0.0477 - val_accuracy: 0.7326\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0483 - accuracy: 0.7270 - val_loss: 0.0474 - val_accuracy: 0.7348\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0480 - accuracy: 0.7290 - val_loss: 0.0471 - val_accuracy: 0.7371\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0477 - accuracy: 0.7312 - val_loss: 0.0468 - val_accuracy: 0.7398\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0474 - accuracy: 0.7335 - val_loss: 0.0465 - val_accuracy: 0.7421\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0471 - accuracy: 0.7354 - val_loss: 0.0462 - val_accuracy: 0.7446\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0468 - accuracy: 0.7373 - val_loss: 0.0459 - val_accuracy: 0.7477\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0465 - accuracy: 0.7394 - val_loss: 0.0456 - val_accuracy: 0.7511\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0462 - accuracy: 0.7416 - val_loss: 0.0453 - val_accuracy: 0.7531\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0459 - accuracy: 0.7433 - val_loss: 0.0451 - val_accuracy: 0.7552\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0456 - accuracy: 0.7451 - val_loss: 0.0448 - val_accuracy: 0.7578\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0453 - accuracy: 0.7476 - val_loss: 0.0445 - val_accuracy: 0.7601\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0451 - accuracy: 0.7492 - val_loss: 0.0442 - val_accuracy: 0.7620\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0448 - accuracy: 0.7517 - val_loss: 0.0439 - val_accuracy: 0.7638\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0445 - accuracy: 0.7535 - val_loss: 0.0437 - val_accuracy: 0.7663\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0442 - accuracy: 0.7556 - val_loss: 0.0434 - val_accuracy: 0.7687\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0440 - accuracy: 0.7578 - val_loss: 0.0431 - val_accuracy: 0.7704\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0437 - accuracy: 0.7600 - val_loss: 0.0428 - val_accuracy: 0.7724\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0434 - accuracy: 0.7620 - val_loss: 0.0426 - val_accuracy: 0.7740\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0432 - accuracy: 0.7637 - val_loss: 0.0423 - val_accuracy: 0.7754\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0429 - accuracy: 0.7659 - val_loss: 0.0420 - val_accuracy: 0.7770\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0427 - accuracy: 0.7678 - val_loss: 0.0418 - val_accuracy: 0.7794\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0424 - accuracy: 0.7699 - val_loss: 0.0415 - val_accuracy: 0.7821\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0422 - accuracy: 0.7720 - val_loss: 0.0413 - val_accuracy: 0.7850\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0419 - accuracy: 0.7738 - val_loss: 0.0410 - val_accuracy: 0.7871\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0417 - accuracy: 0.7757 - val_loss: 0.0408 - val_accuracy: 0.7887\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0414 - accuracy: 0.7775 - val_loss: 0.0405 - val_accuracy: 0.7908\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0412 - accuracy: 0.7799 - val_loss: 0.0403 - val_accuracy: 0.7927\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0409 - accuracy: 0.7814 - val_loss: 0.0400 - val_accuracy: 0.7941\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0407 - accuracy: 0.7836 - val_loss: 0.0398 - val_accuracy: 0.7963\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0404 - accuracy: 0.7855 - val_loss: 0.0395 - val_accuracy: 0.7988\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0402 - accuracy: 0.7875 - val_loss: 0.0393 - val_accuracy: 0.8006\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0400 - accuracy: 0.7893 - val_loss: 0.0391 - val_accuracy: 0.8035\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0397 - accuracy: 0.7911 - val_loss: 0.0388 - val_accuracy: 0.8056\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0395 - accuracy: 0.7932 - val_loss: 0.0386 - val_accuracy: 0.8074\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0393 - accuracy: 0.7949 - val_loss: 0.0384 - val_accuracy: 0.8084\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0391 - accuracy: 0.7966 - val_loss: 0.0382 - val_accuracy: 0.8111\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0388 - accuracy: 0.7984 - val_loss: 0.0379 - val_accuracy: 0.8125\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0386 - accuracy: 0.8001 - val_loss: 0.0377 - val_accuracy: 0.8137\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0384 - accuracy: 0.8018 - val_loss: 0.0375 - val_accuracy: 0.8156\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0382 - accuracy: 0.8039 - val_loss: 0.0373 - val_accuracy: 0.8173\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0380 - accuracy: 0.8048 - val_loss: 0.0371 - val_accuracy: 0.8188\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0378 - accuracy: 0.8066 - val_loss: 0.0368 - val_accuracy: 0.8197\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0375 - accuracy: 0.8080 - val_loss: 0.0366 - val_accuracy: 0.8211\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0373 - accuracy: 0.8092 - val_loss: 0.0364 - val_accuracy: 0.8219\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0371 - accuracy: 0.8109 - val_loss: 0.0362 - val_accuracy: 0.8230\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0369 - accuracy: 0.8127 - val_loss: 0.0360 - val_accuracy: 0.8237\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0367 - accuracy: 0.8143 - val_loss: 0.0358 - val_accuracy: 0.8248\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0365 - accuracy: 0.8157 - val_loss: 0.0356 - val_accuracy: 0.8264\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0363 - accuracy: 0.8169 - val_loss: 0.0354 - val_accuracy: 0.8275\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0361 - accuracy: 0.8180 - val_loss: 0.0352 - val_accuracy: 0.8285\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0359 - accuracy: 0.8193 - val_loss: 0.0350 - val_accuracy: 0.8294\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0358 - accuracy: 0.8204 - val_loss: 0.0348 - val_accuracy: 0.8304\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0356 - accuracy: 0.8216 - val_loss: 0.0346 - val_accuracy: 0.8310\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0354 - accuracy: 0.8223 - val_loss: 0.0344 - val_accuracy: 0.8319\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0352 - accuracy: 0.8234 - val_loss: 0.0343 - val_accuracy: 0.8323\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0350 - accuracy: 0.8245 - val_loss: 0.0341 - val_accuracy: 0.8330\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0348 - accuracy: 0.8257 - val_loss: 0.0339 - val_accuracy: 0.8335\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0347 - accuracy: 0.8266 - val_loss: 0.0337 - val_accuracy: 0.8343\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0345 - accuracy: 0.8275 - val_loss: 0.0335 - val_accuracy: 0.8347\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0343 - accuracy: 0.8291 - val_loss: 0.0334 - val_accuracy: 0.8360\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0341 - accuracy: 0.8298 - val_loss: 0.0332 - val_accuracy: 0.8366\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0340 - accuracy: 0.8307 - val_loss: 0.0330 - val_accuracy: 0.8376\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0338 - accuracy: 0.8314 - val_loss: 0.0328 - val_accuracy: 0.8386\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0336 - accuracy: 0.8321 - val_loss: 0.0327 - val_accuracy: 0.8400\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0335 - accuracy: 0.8328 - val_loss: 0.0325 - val_accuracy: 0.8411\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0333 - accuracy: 0.8339 - val_loss: 0.0323 - val_accuracy: 0.8422\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0331 - accuracy: 0.8346 - val_loss: 0.0322 - val_accuracy: 0.8433\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0330 - accuracy: 0.8353 - val_loss: 0.0320 - val_accuracy: 0.8442\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0328 - accuracy: 0.8361 - val_loss: 0.0319 - val_accuracy: 0.8452\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0327 - accuracy: 0.8368 - val_loss: 0.0317 - val_accuracy: 0.8455\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0325 - accuracy: 0.8372 - val_loss: 0.0315 - val_accuracy: 0.8463\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0323 - accuracy: 0.8376 - val_loss: 0.0314 - val_accuracy: 0.8464\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0322 - accuracy: 0.8384 - val_loss: 0.0312 - val_accuracy: 0.8472\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0320 - accuracy: 0.8393 - val_loss: 0.0311 - val_accuracy: 0.8478\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0319 - accuracy: 0.8400 - val_loss: 0.0309 - val_accuracy: 0.8485\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0318 - accuracy: 0.8408 - val_loss: 0.0308 - val_accuracy: 0.8489\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0316 - accuracy: 0.8414 - val_loss: 0.0307 - val_accuracy: 0.8495\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0315 - accuracy: 0.8419 - val_loss: 0.0305 - val_accuracy: 0.8505\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0313 - accuracy: 0.8423 - val_loss: 0.0304 - val_accuracy: 0.8512\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0312 - accuracy: 0.8428 - val_loss: 0.0302 - val_accuracy: 0.8521\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0310 - accuracy: 0.8437 - val_loss: 0.0301 - val_accuracy: 0.8525\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0309 - accuracy: 0.8440 - val_loss: 0.0300 - val_accuracy: 0.8532\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0308 - accuracy: 0.8448 - val_loss: 0.0298 - val_accuracy: 0.8535\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0306 - accuracy: 0.8453 - val_loss: 0.0297 - val_accuracy: 0.8534\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0305 - accuracy: 0.8457 - val_loss: 0.0295 - val_accuracy: 0.8540\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0304 - accuracy: 0.8463 - val_loss: 0.0294 - val_accuracy: 0.8546\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0303 - accuracy: 0.8468 - val_loss: 0.0293 - val_accuracy: 0.8555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fef52e12f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwcd0u-ug6NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}